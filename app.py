import streamlit as st
from google import genai

st.set_page_config(page_title="Gemini Models Explorer", page_icon="ğŸ”", layout="wide")

st.title("ğŸ” Gemini Models Explorer")
st.write("×¨×©×™××ª ××•×“×œ×™ Gemini ×©× ×™×ª×Ÿ ×œ×”×©×ª××© ×‘×”× ××”××¤×œ×™×§×¦×™×” ×©×œ×š, ×›×•×œ×œ ×¡×•×’ ×©×™××•×© ××•××œ×¥.")

# --- ×§×¨×™××ª ××¤×ª×— ××”-secrets ---
API_KEY = (
    st.secrets.get("GOOGLE_API_KEY")
    or st.secrets.get("GEMINI_API_KEY")
)

if not API_KEY:
    st.error("×—×¡×¨ ××¤×ª×— API. ×”×’×“×¨ GOOGLE_API_KEY ××• GEMINI_API_KEY ×‘Ö¾secrets.toml ×©×œ Streamlit.")
    st.stop()

# ×™×¦×™×¨×ª ×œ×§×•×— ×œ-Gemini Developer API
client = genai.Client(api_key=API_KEY)


# --- Fallback ×¡×˜×˜×™ (×œ××§×¨×” ×©×”-API ×œ× ××—×–×™×¨ ×›×œ×•×) ---
FALLBACK_MODELS = [
    {"id": "gemini-2.5-pro", "category": "Chat / Reasoning", "notes": "××•×“×œ ×—×–×§ ×œ×—×©×™×‘×” ××¨×•×‘×ª ×©×œ×‘×™×, ×§×•×“ ×•× ×™×ª×•×— ××•×¨×›×‘."},
    {"id": "gemini-2.5-flash", "category": "Chat / General", "notes": "××”×™×¨ ×•×–×•×œ ×™×—×¡×™×ª, ××ª××™× ×œ×¦'××˜, ×¡×™×›×•××™× ×•×¢×•××¡ ×’×‘×•×”."},
    {"id": "gemini-2.5-flash-lite", "category": "Chat / Cost-Optimized", "notes": "×’×¨×¡×” ×§×œ×” ×•×–×•×œ×” ×œ×¢×•××¡×™× ×›×‘×“×™× ×•-latency × ××•×š."},
    {"id": "gemini-3-pro-preview", "category": "Chat / Reasoning (Preview)", "notes": "×“×•×¨ ×—×“×©, ×›×¨×’×¢ ×‘-Preview â€“ ××•××œ×¥ ×œ-POC ×‘×œ×‘×“."},
    {"id": "gemini-flash-latest", "category": "Chat / General (Alias)", "notes": "Alias ×œ××•×“×œ Flash ×”××—×¨×•×Ÿ."},
    {"id": "gemini-pro-latest", "category": "Chat / Reasoning (Alias)", "notes": "Alias ×œ××•×“×œ Pro ×”××—×¨×•×Ÿ."},
    {"id": "text-embedding-004", "category": "Embeddings", "notes": "××•×“×œ embedding ×œ××©×™××•×ª ×—×™×¤×•×© ×•-clustering."},
    {"id": "gemini-embedding-001", "category": "Embeddings", "notes": "××•×“×œ embedding × ×•×¡×£, ××ª××™× ×œ×™×™×©×•××™ ×˜×§×¡×˜ ×›×œ×œ×™×™×."},
    {"id": "imagen-4.0-generate-001", "category": "Image Generation", "notes": "×™×¦×™×¨×ª ×ª××•× ×•×ª ××˜×§×¡×˜."},
    {"id": "veo-3.0-generate-001", "category": "Video Generation", "notes": "×™×¦×™×¨×ª ×•×™×“××• ××˜×§×¡×˜/×ª×™××•×¨."},
]


def classify_type(short_id: str) -> str:
    sid = short_id.lower()

    if "embedding" in sid:
        return "Embeddings"

    if "imagen" in sid or "veo" in sid or "image" in sid:
        return "Image / Video"

    if "live" in sid or "tts" in sid or "native-audio" in sid or "audio" in sid:
        return "Audio / Live"

    if "gemma" in sid:
        return "Chat / Lightweight (Gemma)"

    if "gemini" in sid:
        return "Chat / General"

    return "Other / Tools"


def is_recommended(short_id: str) -> bool:
    sid = short_id.lower()
    recommended_ids = [
        "gemini-2.5-flash",
        "gemini-2.5-pro",
        "gemini-flash-latest",
        "gemini-pro-latest",
        "gemini-3-pro-preview",
        "text-embedding-004",
        "gemini-embedding-001",
        "imagen-4.0-generate-001",
        "veo-3.0-generate-001",
    ]
    return any(sid == r or sid.endswith("/" + r) for r in recommended_ids)


@st.cache_data(show_spinner=True)
def fetch_models_from_api():
    """× ×™×¡×™×•×Ÿ ×œ×”×‘×™× ×¨×©×™××ª ××•×“×œ×™× ××”-Gemini API. ×× ×¨×™×§ â€“ × ×—×–×™×¨ []."""
    items = []
    try:
        pager = client.models.list()
        for m in pager:
            name = getattr(m, "name", "") or getattr(m, "model", "")
            if not name:
                continue

            short_id = name.split("/")[-1]

            display_name = getattr(m, "display_name", "") or ""
            description = getattr(m, "description", "") or ""

            items.append(
                {
                    "full_id": name,
                    "id": short_id,
                    "display_name": display_name,
                    "description": description,
                    "type": classify_type(short_id),
                    "recommended": is_recommended(short_id),
                }
            )
    except Exception as e:
        st.warning(f"models.list() × ×›×©×œ ××”-API: {e}")
    return items


api_models = fetch_models_from_api()

# --- ×¤×™×œ×˜×¨×™× ×‘×¦×“ ---
with st.sidebar:
    st.header("âš™ï¸ ×¤×™×œ×˜×¨×™×")
    show_only_recommended = st.checkbox("×¨×§ ××•×“×œ×™× ××•××œ×¦×™× ×œ×©×™××•×© ×©×•×˜×£", value=True)
    type_filter = st.multiselect(
        "×¡×™× ×•×Ÿ ×œ×¤×™ ×¡×•×’ ××•×“×œ",
        options=["Chat / General", "Chat / Lightweight (Gemma)", "Embeddings", "Image / Video", "Audio / Live", "Other / Tools"],
        default=["Chat / General", "Chat / Lightweight (Gemma)", "Embeddings", "Image / Video", "Audio / Live"],
    )
    search_text = st.text_input("ğŸ” ×—×™×¤×•×© ×œ×¤×™ ×©×/×ª×™××•×¨/ID:", value="")

# --- ×ª×¦×•×’×ª API ---

st.subheader("×ª×•×¦××” ××”-API ×”×¨×©××™")

if len(api_models) == 0:
    st.info(
        "×”-SDK ×œ× ×”×—×–×™×¨ ××•×“×œ×™× (0 ×ª×•×¦××•×ª). "
        "×–×” ×™×›×•×œ ×œ×”×™×•×ª ×‘×’×œ×œ ×¡×•×’ ×”×—×©×‘×•×Ÿ/××¤×ª×—. "
        "×œ××˜×” ×ª×•×¦×’ ×¨×©×™××ª ××•×“×œ×™× ×¡×˜× ×“×¨×˜×™×ª ×œ×¤×™ ×”×“×•×§×•×× ×˜×¦×™×”."
    )
    st.write("ğŸ“¦ × ××¦××• **0 ××•×“×œ×™×** ××”-API.")
else:
    # ×¡×™× ×•×Ÿ
    filtered_api = []
    q = (search_text or "").strip().lower()

    for m in api_models:
        if m["type"] not in type_filter:
            continue
        if show_only_recommended and not m["recommended"]:
            continue

        blob = " ".join(
            [
                str(m.get("id", "")),
                str(m.get("full_id", "")),
                str(m.get("display_name", "")),
                str(m.get("description", "")),
                str(m.get("type", "")),
            ]
        ).lower()
        if q and q not in blob:
            continue

        filtered_api.append(m)

    st.write(f"ğŸ“¦ × ××¦××• **{len(filtered_api)}** ××•×“×œ×™× ××—×¨×™ ×¡×™× ×•×Ÿ.")

    # ×˜×‘×œ×” ×§×•××¤×§×˜×™×ª
    if filtered_api:
        table_data = [
            {
                "ID ×§×¦×¨": m["id"],
                "ID ××œ×": m["full_id"],
                "×¡×•×’": m["type"],
                "××•××œ×¥": "âœ…" if m["recommended"] else "",
                "Display Name": m["display_name"],
            }
            for m in filtered_api
        ]
        st.dataframe(table_data, use_container_width=True)

    # ×¤×™×¨×•×˜ ×œ×›×œ ××•×“×œ
    st.markdown("---")
    for m in filtered_api:
        with st.expander(f'{m["id"]}  Â·  {m["type"]}', expanded=False):
            st.write("**ID ××œ×:**", m.get("full_id", "â€”"))
            st.write("**Display Name:**", m.get("display_name") or "â€”")
            st.write("**×¡×•×’:**", m.get("type", "â€”"))
            st.write("**××•××œ×¥ ×œ×©×™××•×© ×©×•×˜×£:**", "âœ… ×›×Ÿ" if m.get("recommended") else "â€”")
            st.write("**Description:**", m.get("description") or "â€”")

st.markdown("---")

# --- ×ª×¦×•×’×ª Fallback ×¡×˜×˜×™ ---

st.subheader("Fallback â€“ ×¨×©×™××ª ××•×“×œ×™× ×¡×˜× ×“×¨×˜×™×ª ×œ×¤×™ ×”×“×•×§×•×× ×˜×¦×™×”")

search_fb = st.text_input("×—×™×¤×•×© ×‘××•×“×œ×™ fallback (id / category / ×”×¢×¨×•×ª):", key="search_fb")
q_fb = (search_fb or "").strip().lower()

filtered_fb = []
for m in FALLBACK_MODELS:
    blob = " ".join(
        [
            str(m.get("id", "")),
            str(m.get("category", "")),
            str(m.get("notes", "")),
        ]
    ).lower()
    if q_fb and q_fb not in blob:
        continue
    filtered_fb.append(m)

st.write(f"ğŸ“¦ × ××¦××• **{len(filtered_fb)}** ××•×“×œ×™× ×‘×¨×©×™××ª ×”-fallback.")

for m in filtered_fb:
    with st.expander(str(m.get("id", "")), expanded=False):
        st.write("**×§×˜×’×•×¨×™×”:**", m.get("category", "â€”"))
        st.write("**×”×¢×¨×•×ª:**", m.get("notes", "â€”"))
