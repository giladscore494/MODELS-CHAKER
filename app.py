import streamlit as st
from google import genai

st.set_page_config(page_title="Gemini Models Explorer", page_icon="ğŸ”", layout="centered")

st.title("ğŸ” Gemini Models Explorer")
st.write("×¨×©×™××ª ××•×“×œ×™ Gemini ×©× ×™×ª×Ÿ ×œ×”×©×ª××© ×‘×”× ××”××¤×œ×™×§×¦×™×”.")

# --- ×§×¨×™××ª ××¤×ª×— ××”-secrets ---
API_KEY = (
    st.secrets.get("GOOGLE_API_KEY")
    or st.secrets.get("GEMINI_API_KEY")
)

if not API_KEY:
    st.error("×—×¡×¨ ××¤×ª×— API. ×”×’×“×¨ GOOGLE_API_KEY ××• GEMINI_API_KEY ×‘Ö¾secrets.toml ×©×œ Streamlit.")
    st.stop()

# ×™×¦×™×¨×ª ×œ×§×•×— ×œ-Gemini Developer API
client = genai.Client(api_key=API_KEY)

# ×¨×©×™××ª ××•×“×œ×™× ×¡×˜× ×“×¨×˜×™×ª ×œ×¤×™ ×”×“×•×§×•×× ×˜×¦×™×” ×©×œ Gemini (fallback)
FALLBACK_MODELS = [
    {
        "id": "gemini-2.5-pro",
        "category": "Chat / Reasoning",
        "notes": "×”××•×“×œ ×”×—×–×§ ×œ×—×©×™×‘×” ××¨×•×‘×ª ×©×œ×‘×™×, ×§×•×“ ×•× ×™×ª×•×— ××•×¨×›×‘.",
    },
    {
        "id": "gemini-2.5-flash",
        "category": "Chat / General",
        "notes": "××•×“×œ ××”×™×¨ ×•×–×•×œ ×™×—×¡×™×ª, ××ª××™× ×œ×¦'××˜, ×¡×™×›×•××™× ×•×¢×•××¡ ×’×‘×•×”.",
    },
    {
        "id": "gemini-2.5-flash-lite",
        "category": "Chat / Cost-Optimized",
        "notes": "×’×¨×¡×” ×§×œ×” ×•×–×•×œ×” ×¢×•×“ ×™×•×ª×¨, ×œ×¢×•××¡×™× ×›×‘×“×™× ×××•×“ ×•-latency × ××•×š.",
    },
    {
        "id": "gemini-2.5-flash-preview-tts",
        "category": "TTS",
        "notes": "×”××¨×ª ×˜×§×¡×˜ ×œ×“×™×‘×•×¨ (Text-To-Speech) â€“ ×’×¨×¡×ª Flash.",
    },
    {
        "id": "gemini-2.5-pro-preview-tts",
        "category": "TTS",
        "notes": "×”××¨×ª ×˜×§×¡×˜ ×œ×“×™×‘×•×¨ â€“ ×’×¨×¡×ª Pro.",
    },
    {
        "id": "gemini-2.0-flash",
        "category": "Chat / General (×“×•×¨ ×§×•×“×)",
        "notes": "××•×“×œ ××”×™×¨ ××”×“×•×¨ ×”×§×•×“×, ×¢×“×™×™×Ÿ ×–××™×Ÿ ×•× ×ª××š ×‘×”×¨×‘×” ××™× ×˜×’×¨×¦×™×•×ª.",
    },
    {
        "id": "gemini-2.0-flash-lite",
        "category": "Chat / Cost-Optimized (×“×•×¨ ×§×•×“×)",
        "notes": "×’×¨×¡×ª Lite ×©×œ 2.0 Flash, ×–×•×œ×” ×•××”×™×¨×”.",
    },
    {
        "id": "gemini-2.0-flash-preview-image-generation",
        "category": "Image Generation",
        "notes": "×™×¦×™×¨×ª ×ª××•× ×•×ª ××˜×§×¡×˜ (×œ× ×–××™×Ÿ ×‘×—×œ×§ ××”××“×™× ×•×ª ×‘××™×¨×•×¤×”/××–×”\"×ª).",
    },
    {
        "id": "gemini-2.0-flash-live-001",
        "category": "Live / Audio",
        "notes": "×©×™×—×•×ª Live ×§×•×œ×™×•×ª/××•×œ×˜×™××•×“×œ ×‘×–××Ÿ ×××ª.",
    },
    {
        "id": "text-embedding-004",
        "category": "Embeddings",
        "notes": "××•×“×œ embedding ×˜×§×¡×˜ ×›×œ×œ×™ ×œ××©×™××•×ª ×—×™×¤×•×©, clustering ×•×¡×× ×˜×™×§×” (×‘×“×¨×š ×œ×“×™×¤×¨×™×§×¦×™×”).",
    },
    {
        "id": "models/embedding-001",
        "category": "Embeddings",
        "notes": "××•×“×œ embedding ×•×ª×™×§ ×™×•×ª×¨, ×¢×“×™×™×Ÿ × ×ª××š ×‘×—×œ×§ ××”×××©×§×™×.",
    },
]

@st.cache_data(show_spinner=True)
def fetch_models_from_api():
    """× ×™×¡×™×•×Ÿ ×œ×”×‘×™× ×¨×©×™××ª ××•×“×œ×™× ××”-Gemini API. ×× ×¨×™×§ â€“ × ×—×–×™×¨ []."""
    items = []
    try:
        pager = client.models.list(config={"page_size": 100})
        for m in pager:
            # ××•×‘×™×™×§×˜ ×”××•×“×œ ××’×™×¢ ××”-SDK, ×œ× ×ª××™×“ ××•×ª×• ××‘× ×” â€“ × ××©×•×š ××” ×©×™×©.
            model_dict = {
                "id": getattr(m, "name", "") or getattr(m, "model", ""),
                "display_name": getattr(m, "display_name", ""),
                "description": getattr(m, "description", ""),
            }
            # ×œ×¡× ×Ÿ ××•×“×œ×™× ×‘×œ×™ id ×‘×›×œ×œ
            if model_dict["id"]:
                items.append(model_dict)
    except Exception as e:
        # × ×¦×™×’ ××–×”×¨×” ×•× ×™×ª×Ÿ ×œ××¤×œ×™×§×¦×™×” ×œ×”××©×™×š ×¢× fallback
        st.warning(f"models.list() × ×›×©×œ ××”-API: {e}")
    return items

api_models = fetch_models_from_api()

# --- UI ---

st.subheader("×ª×•×¦××” ××”-API ×”×¨×©××™")

if len(api_models) == 0:
    st.info(
        "×”-SDK ×œ× ×”×—×–×™×¨ ××•×“×œ×™× (0 ×ª×•×¦××•×ª). "
        "×–×” ×œ×¤×¢××™× ×§×•×¨×” ×× ×”×—×©×‘×•×Ÿ ××•×’×“×¨ ×‘-Vertex AI ×‘×œ×™ ×”×¤×¢×œ×ª Gemini, "
        "××• ×× ××©×ª××©×™× ×‘××¤×ª×— ×œ× × ×›×•×Ÿ. ×œ×›×Ÿ ××¦×™×’×™× ×œ××˜×” ×¨×©×™××ª ××•×“×œ×™× ×¡×˜× ×“×¨×˜×™×ª ×œ×¤×™ ×”×“×•×§×•×× ×˜×¦×™×”."
    )
    st.write("ğŸ“¦ × ××¦××• **0 ××•×“×œ×™×** ××”-API.")
else:
    st.success(f"ğŸ“¦ × ××¦××• **{len(api_models)} ××•×“×œ×™×** ××”-API.")
    search_api = st.text_input("×—×™×¤×•×© ×‘××•×“×œ×™× ××”-API (×©× / ×ª×™××•×¨):", key="search_api")
    filtered_api = []
    q = (search_api or "").strip().lower()
    for m in api_models:
        blob = " ".join(
            [
                m.get("id", ""),
                m.get("display_name", ""),
                m.get("description", ""),
            ]
        ).lower()
        if q in blob:
            filtered_api.append(m)

    st.write(f"ğŸ” ×¡×™× ×•×Ÿ API: **{len(filtered_api)}** ××•×“×œ×™× ×œ××—×¨ ×—×™×¤×•×©.")
    for m in filtered_api:
        with st.expander(m.get("id", "unknown"), expanded=False):
            st.write("**Display Name:**", m.get("display_name") or "â€”")
            st.write("**Description:**", m.get("description") or "â€”")

st.markdown("---")
st.subheader("Fallback â€“ ×¨×©×™××ª ××•×“×œ×™× ×¡×˜× ×“×¨×˜×™×ª ×œ×¤×™ ×”×“×•×§×•×× ×˜×¦×™×”")

search_fb = st.text_input("×—×™×¤×•×© ×‘××•×“×œ×™ fallback (id / category / ×”×¢×¨×•×ª):", key="search_fb")
q_fb = (search_fb or "").strip().lower()

filtered_fb = []
for m in FALLBACK_MODELS:
    blob = " ".join([m["id"], m["category"], m["notes"]]).lower()
    if q_fb in blob:
        filtered_fb.append(m)

st.write(f"ğŸ“¦ × ××¦××• **{len(filtered_fb)}** ××•×“×œ×™× ×‘×¨×©×™××ª ×”-fallback.")

for m in filtered_fb:
    with st.expander(m["id"], expanded=False):
        st.write("**×§×˜×’×•×¨×™×”:**", m["category"])
        st.write("**×”×¢×¨×•×ª:**", m["notes"])
