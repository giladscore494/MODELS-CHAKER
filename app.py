import streamlit as st
from google import genai

st.set_page_config(page_title="Gemini Models Explorer", page_icon="ğŸ”", layout="centered")

st.title("ğŸ” Gemini Models Explorer")
st.write("×¨×©×™××ª ××•×“×œ×™ Gemini ×©× ×™×ª×Ÿ ×œ×”×©×ª××© ×‘×”× ××”××¤×œ×™×§×¦×™×”.")

# --- ×§×¨×™××ª ××¤×ª×— ××”-secrets ---
API_KEY = (
    st.secrets.get("GOOGLE_API_KEY")
    or st.secrets.get("GEMINI_API_KEY")
)

if not API_KEY:
    st.error("×—×¡×¨ ××¤×ª×— API. ×”×’×“×¨ GOOGLE_API_KEY ××• GEMINI_API_KEY ×‘Ö¾secrets.toml ×©×œ Streamlit.")
    st.stop()

# ×™×¦×™×¨×ª ×œ×§×•×— ×œ-Gemini Developer API
client = genai.Client(api_key=API_KEY)

# ×¨×©×™××ª ××•×“×œ×™× ×¡×˜× ×“×¨×˜×™×ª ×œ×¤×™ ×”×“×•×§×•×× ×˜×¦×™×” ×©×œ Gemini (fallback)
FALLBACK_MODELS = [
    {
        "id": "gemini-2.5-pro",
        "category": "Chat / Reasoning",
        "notes": "××•×“×œ ×—×–×§ ×œ×—×©×™×‘×” ××¨×•×‘×ª ×©×œ×‘×™×, ×§×•×“ ×•× ×™×ª×•×— ××•×¨×›×‘.",
    },
    {
        "id": "gemini-2.5-flash",
        "category": "Chat / General",
        "notes": "××”×™×¨ ×•×–×•×œ ×™×—×¡×™×ª, ××ª××™× ×œ×¦'××˜, ×¡×™×›×•××™× ×•×¢×•××¡ ×’×‘×•×”.",
    },
    {
        "id": "gemini-2.5-flash-lite",
        "category": "Chat / Cost-Optimized",
        "notes": "×’×¨×¡×” ×§×œ×” ×•×–×•×œ×” ×œ×¢×•××¡×™× ×›×‘×“×™× ×•-latency × ××•×š.",
    },
    {
        "id": "gemini-2.5-flash-preview-tts",
        "category": "TTS",
        "notes": "×”××¨×ª ×˜×§×¡×˜ ×œ×“×™×‘×•×¨ (Flash).",
    },
    {
        "id": "gemini-2.5-pro-preview-tts",
        "category": "TTS",
        "notes": "×”××¨×ª ×˜×§×¡×˜ ×œ×“×™×‘×•×¨ (Pro).",
    },
    {
        "id": "gemini-2.0-flash",
        "category": "Chat / General (×“×•×¨ ×§×•×“×)",
        "notes": "××•×“×œ ××”×™×¨ ××”×“×•×¨ ×”×§×•×“×.",
    },
    {
        "id": "gemini-2.0-flash-lite",
        "category": "Chat / Cost-Optimized (×“×•×¨ ×§×•×“×)",
        "notes": "×’×¨×¡×ª Lite ×©×œ 2.0 Flash.",
    },
    {
        "id": "gemini-2.0-flash-preview-image-generation",
        "category": "Image Generation",
        "notes": "×™×¦×™×¨×ª ×ª××•× ×•×ª ××˜×§×¡×˜ (×ª×œ×•×™ ××“×™× ×”).",
    },
    {
        "id": "gemini-2.0-flash-live-001",
        "category": "Live / Audio",
        "notes": "×©×™×—×•×ª Live ×§×•×œ×™×•×ª/××•×œ×˜×™××•×“×œ ×‘×–××Ÿ ×××ª.",
    },
    {
        "id": "text-embedding-004",
        "category": "Embeddings",
        "notes": "××•×“×œ embedding ×œ××©×™××•×ª ×—×™×¤×•×© ×•-clustering.",
    },
    {
        "id": "models/embedding-001",
        "category": "Embeddings",
        "notes": "××•×“×œ embedding ×•×ª×™×§ ×™×•×ª×¨.",
    },
]


@st.cache_data(show_spinner=True)
def fetch_models_from_api():
    """× ×™×¡×™×•×Ÿ ×œ×”×‘×™× ×¨×©×™××ª ××•×“×œ×™× ××”-Gemini API. ×× ×¨×™×§ â€“ × ×—×–×™×¨ []."""
    items = []
    try:
        pager = client.models.list()
        for m in pager:
            # ××•×‘×™×™×§×˜ ×”××•×“×œ ××’×™×¢ ××”-SDK, ×œ× ×ª××™×“ ××•×ª×• ××‘× ×” â€“ × ××©×•×š ××” ×©×™×©.
            name = getattr(m, "name", "") or getattr(m, "model", "")
            display_name = getattr(m, "display_name", "")
            description = getattr(m, "description", "")
            if not name:
                continue
            items.append(
                {
                    "id": name,
                    "display_name": display_name,
                    "description": description,
                }
            )
    except Exception as e:
        st.warning(f"models.list() × ×›×©×œ ××”-API: {e}")
    return items


api_models = fetch_models_from_api()

# --- ×ª×¦×•×’×ª API ---

st.subheader("×ª×•×¦××” ××”-API ×”×¨×©××™")

if len(api_models) == 0:
    st.info(
        "×”-SDK ×œ× ×”×—×–×™×¨ ××•×“×œ×™× (0 ×ª×•×¦××•×ª). "
        "×–×” ×™×›×•×œ ×œ×”×™×•×ª ×‘×’×œ×œ ×¡×•×’ ×”×—×©×‘×•×Ÿ/××¤×ª×—. "
        "×œ××˜×” ×ª×•×¦×’ ×¨×©×™××ª ××•×“×œ×™× ×¡×˜× ×“×¨×˜×™×ª ×œ×¤×™ ×”×“×•×§×•×× ×˜×¦×™×”."
    )
    st.write("ğŸ“¦ × ××¦××• **0 ××•×“×œ×™×** ××”-API.")
else:
    st.success(f"ğŸ“¦ × ××¦××• **{len(api_models)} ××•×“×œ×™×** ××”-API.")
    search_api = st.text_input("×—×™×¤×•×© ×‘××•×“×œ×™× ××”-API (×©× / ×ª×™××•×¨):", key="search_api")
    q = (search_api or "").strip().lower()

    filtered_api = []
    for m in api_models:
        blob = " ".join(
            [
                str(m.get("id", "")),
                str(m.get("display_name", "")),
                str(m.get("description", "")),
            ]
        ).lower()
        if q in blob:
            filtered_api.append(m)

    st.write(f"ğŸ” ×¡×™× ×•×Ÿ API: **{len(filtered_api)}** ××•×“×œ×™× ×œ××—×¨ ×—×™×¤×•×©.")
    for m in filtered_api:
        with st.expander(str(m.get("id", "unknown")), expanded=False):
            st.write("**Display Name:**", m.get("display_name") or "â€”")
            st.write("**Description:**", m.get("description") or "â€”")

st.markdown("---")

# --- ×ª×¦×•×’×ª Fallback ---

st.subheader("Fallback â€“ ×¨×©×™××ª ××•×“×œ×™× ×¡×˜× ×“×¨×˜×™×ª ×œ×¤×™ ×”×“×•×§×•×× ×˜×¦×™×”")

search_fb = st.text_input("×—×™×¤×•×© ×‘××•×“×œ×™ fallback (id / category / ×”×¢×¨×•×ª):", key="search_fb")
q_fb = (search_fb or "").strip().lower()

filtered_fb = []
for m in FALLBACK_MODELS:
    blob = " ".join(
        [
            str(m.get("id", "")),
            str(m.get("category", "")),
            str(m.get("notes", "")),
        ]
    ).lower()
    if q_fb in blob:
        filtered_fb.append(m)

st.write(f"ğŸ“¦ × ××¦××• **{len(filtered_fb)}** ××•×“×œ×™× ×‘×¨×©×™××ª ×”-fallback.")

for m in filtered_fb:
    with st.expander(str(m.get("id", "")), expanded=False):
        st.write("**×§×˜×’×•×¨×™×”:**", m.get("category", "â€”"))
        st.write("**×”×¢×¨×•×ª:**", m.get("notes", "â€”"))
